{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"try:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom keras.models import Sequential","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocessing function\ndef map_image(image, label):\n  image = tf.cast(image, dtype=tf.float32)\n  image = image / 255.0\n\n  return image, image # dataset label is not used. replaced with the same image input.","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters\nBATCH_SIZE = 128\nSHUFFLE_BUFFER_SIZE = 1024\n\n\n### START CODE HERE (Replace instances of `None` with your code) ###\n\n# use tfds.load() to fetch the 'train' split of CIFAR-10\ntrain_dataset = tfds.load('cifar10', as_supervised=True, split=\"train\")\n\n# preprocess the dataset with the `map_image()` function above\ntrain_dataset = train_dataset.map(map_image)\n\n# shuffle and batch the dataset\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\n\n# use tfds.load() to fetch the 'test' split of CIFAR-10\ntest_dataset = tfds.load('cifar10', as_supervised=True, split=\"test\")\n\n# preprocess the dataset with the `map_image()` function above\ntest_dataset = test_dataset.map(map_image)\n\n# batch the dataset\ntest_dataset = test_dataset.batch(BATCH_SIZE).repeat()\n\n### END CODE HERE ###","execution_count":4,"outputs":[{"output_type":"stream","text":"\u001b[1mDownloading and preparing dataset cifar10/3.0.2 (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to /root/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ab542ab04549bfb56bbcf51b2c3349"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce252d197b03479693d59288151172a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f54b4f33e8745e1b6d97d8c75a26bf6"}},"metadata":{}},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.cs.toronto.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning,\n","name":"stderr"},{"output_type":"stream","text":"\n\n\n\n\n\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Shuffling and writing examples to /root/tensorflow_datasets/cifar10/3.0.2.incompleteFB5NB6/cifar10-train.tfrecord\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1541aabfd48c4af4bd647370c4c1b8f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"Shuffling and writing examples to /root/tensorflow_datasets/cifar10/3.0.2.incompleteFB5NB6/cifar10-test.tfrecord\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5f242f1f3b64163a8316b1eb9679658"}},"metadata":{}},{"output_type":"stream","text":"\u001b[1mDataset cifar10 downloaded and prepared to /root/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# suggested layers to use. feel free to add or remove as you see fit.\nfrom keras.layers import Conv2D, UpSampling2D\n\n# use the Sequential API (you can remove if you want to use the Functional API)\n\n\n### START CODE HERE ###\n# use `model.add()` to add layers (if using the Sequential API)\ndef encoder(inputs):\n  '''Defines the encoder with two Conv2D and max pooling layers.'''\n  conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n  max_pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_1)\n\n  conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(max_pool_1)\n  max_pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_2)\n\n  return max_pool_2\n\n\ndef bottle_neck(inputs):\n  '''Defines the bottleneck.'''\n  bottle_neck = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n  encoder_visualization = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(bottle_neck)\n\n  return bottle_neck, encoder_visualization\n\ndef decoder(inputs):\n  '''Defines the decoder path to upsample back to the original image size.'''\n  conv_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n  up_sample_1 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_1)\n\n  conv_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(up_sample_1)\n  up_sample_2 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_2)\n\n  conv_3 = tf.keras.layers.Conv2D(filters=3, kernel_size=(3,3), activation='sigmoid', padding='same')(up_sample_2)\n\n  return conv_3\n\n\n### END CODE HERE ###","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolutional_auto_encoder():\n  '''Builds the entire autoencoder model.'''\n  inputs = tf.keras.layers.Input(shape=(32, 32, 3,))\n  encoder_output = encoder(inputs)\n  bottleneck_output, encoder_visualization = bottle_neck(encoder_output)\n  decoder_output = decoder(bottleneck_output)\n  \n  model = tf.keras.Model(inputs =inputs, outputs=decoder_output)\n  encoder_model = tf.keras.Model(inputs=inputs, outputs=encoder_visualization)\n  return model, encoder_model\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convolutional_model, convolutional_encoder_model = convolutional_auto_encoder()\nconvolutional_model.summary()","execution_count":7,"outputs":[{"output_type":"stream","text":"Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 32, 32, 64)        1792      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 8, 8, 128)         295040    \n_________________________________________________________________\nup_sampling2d (UpSampling2D) (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 16, 16, 64)        73792     \n_________________________________________________________________\nup_sampling2d_1 (UpSampling2 (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 32, 32, 3)         1731      \n=================================================================\nTotal params: 741,379\nTrainable params: 741,379\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Please do not change the model.compile() parameters\nconvolutional_model.compile(optimizer='adam', metrics=['accuracy'], loss='mean_squared_error')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters\ntrain_steps = 60000 // BATCH_SIZE \nval_steps = 60000 // BATCH_SIZE\n\n### START CODE HERE ###\nconvolutional_model.fit(train_dataset, steps_per_epoch=train_steps, validation_data=test_dataset, validation_steps=val_steps, epochs=40)\n### END CODE HERE ###","execution_count":9,"outputs":[{"output_type":"stream","text":"Epoch 1/40\n468/468 [==============================] - 21s 45ms/step - loss: 0.0090 - accuracy: 0.7464 - val_loss: 0.0042 - val_accuracy: 0.8048\nEpoch 2/40\n468/468 [==============================] - 12s 25ms/step - loss: 0.0036 - accuracy: 0.8118 - val_loss: 0.0031 - val_accuracy: 0.8280\nEpoch 3/40\n468/468 [==============================] - 12s 26ms/step - loss: 0.0029 - accuracy: 0.8187 - val_loss: 0.0029 - val_accuracy: 0.8282\nEpoch 4/40\n468/468 [==============================] - 12s 27ms/step - loss: 0.0024 - accuracy: 0.8223 - val_loss: 0.0028 - val_accuracy: 0.8277\nEpoch 5/40\n468/468 [==============================] - 12s 25ms/step - loss: 0.0021 - accuracy: 0.8246 - val_loss: 0.0019 - val_accuracy: 0.8407\nEpoch 6/40\n468/468 [==============================] - 12s 25ms/step - loss: 0.0020 - accuracy: 0.8248 - val_loss: 0.0017 - val_accuracy: 0.8427\nEpoch 7/40\n468/468 [==============================] - 12s 25ms/step - loss: 0.0018 - accuracy: 0.8302 - val_loss: 0.0016 - val_accuracy: 0.8452\nEpoch 8/40\n468/468 [==============================] - 11s 24ms/step - loss: 0.0017 - accuracy: 0.8319 - val_loss: 0.0015 - val_accuracy: 0.8524\nEpoch 9/40\n468/468 [==============================] - 12s 25ms/step - loss: 0.0016 - accuracy: 0.8337 - val_loss: 0.0015 - val_accuracy: 0.8355\nEpoch 10/40\n468/468 [==============================] - 11s 24ms/step - loss: 0.0015 - accuracy: 0.8343 - val_loss: 0.0014 - val_accuracy: 0.8522\nEpoch 11/40\n468/468 [==============================] - 11s 24ms/step - loss: 0.0014 - accuracy: 0.8373 - val_loss: 0.0013 - val_accuracy: 0.8572\nEpoch 12/40\n468/468 [==============================] - 12s 26ms/step - loss: 0.0014 - accuracy: 0.8381 - val_loss: 0.0013 - val_accuracy: 0.8203\nEpoch 13/40\n468/468 [==============================] - 11s 24ms/step - loss: 0.0013 - accuracy: 0.8405 - val_loss: 0.0014 - val_accuracy: 0.8463\nEpoch 14/40\n468/468 [==============================] - 12s 26ms/step - loss: 0.0013 - accuracy: 0.8410 - val_loss: 0.0012 - val_accuracy: 0.8596\nEpoch 15/40\n468/468 [==============================] - 12s 25ms/step - loss: 0.0012 - accuracy: 0.8419 - val_loss: 0.0012 - val_accuracy: 0.8561\nEpoch 16/40\n468/468 [==============================] - 11s 24ms/step - loss: 0.0012 - accuracy: 0.8448 - val_loss: 0.0011 - val_accuracy: 0.8559\nEpoch 17/40\n468/468 [==============================] - 12s 25ms/step - loss: 0.0011 - accuracy: 0.8469 - val_loss: 0.0011 - val_accuracy: 0.8552\nEpoch 18/40\n468/468 [==============================] - 11s 24ms/step - loss: 0.0011 - accuracy: 0.8467 - val_loss: 0.0012 - val_accuracy: 0.8376\nEpoch 19/40\n468/468 [==============================] - 11s 23ms/step - loss: 0.0011 - accuracy: 0.8480 - val_loss: 0.0011 - val_accuracy: 0.8628\nEpoch 20/40\n468/468 [==============================] - 12s 26ms/step - loss: 0.0010 - accuracy: 0.8490 - val_loss: 0.0010 - val_accuracy: 0.8459\nEpoch 21/40\n468/468 [==============================] - 11s 24ms/step - loss: 0.0010 - accuracy: 0.8502 - val_loss: 0.0011 - val_accuracy: 0.8643\nEpoch 22/40\n468/468 [==============================] - 11s 24ms/step - loss: 9.9811e-04 - accuracy: 0.8509 - val_loss: 9.7773e-04 - val_accuracy: 0.8487\nEpoch 23/40\n468/468 [==============================] - 12s 25ms/step - loss: 9.8086e-04 - accuracy: 0.8515 - val_loss: 9.9209e-04 - val_accuracy: 0.8603\nEpoch 24/40\n468/468 [==============================] - 11s 23ms/step - loss: 0.0011 - accuracy: 0.8487 - val_loss: 0.0014 - val_accuracy: 0.8527\nEpoch 25/40\n468/468 [==============================] - 11s 24ms/step - loss: 9.3578e-04 - accuracy: 0.8541 - val_loss: 8.8950e-04 - val_accuracy: 0.8690\nEpoch 26/40\n468/468 [==============================] - 12s 26ms/step - loss: 9.2549e-04 - accuracy: 0.8547 - val_loss: 9.9379e-04 - val_accuracy: 0.8590\nEpoch 27/40\n468/468 [==============================] - 11s 24ms/step - loss: 9.0820e-04 - accuracy: 0.8549 - val_loss: 8.5237e-04 - val_accuracy: 0.8676\nEpoch 28/40\n468/468 [==============================] - 13s 27ms/step - loss: 9.0158e-04 - accuracy: 0.8555 - val_loss: 8.4185e-04 - val_accuracy: 0.8565\nEpoch 29/40\n468/468 [==============================] - 11s 24ms/step - loss: 8.8291e-04 - accuracy: 0.8564 - val_loss: 9.1428e-04 - val_accuracy: 0.8622\nEpoch 30/40\n468/468 [==============================] - 12s 25ms/step - loss: 8.6598e-04 - accuracy: 0.8561 - val_loss: 8.6224e-04 - val_accuracy: 0.8477\nEpoch 31/40\n468/468 [==============================] - 12s 25ms/step - loss: 8.5196e-04 - accuracy: 0.8580 - val_loss: 9.1684e-04 - val_accuracy: 0.8576\nEpoch 32/40\n468/468 [==============================] - 11s 24ms/step - loss: 8.4450e-04 - accuracy: 0.8578 - val_loss: 8.9417e-04 - val_accuracy: 0.8672\nEpoch 33/40\n468/468 [==============================] - 11s 25ms/step - loss: 8.2649e-04 - accuracy: 0.8592 - val_loss: 8.6039e-04 - val_accuracy: 0.8693\nEpoch 34/40\n468/468 [==============================] - 11s 24ms/step - loss: 8.2447e-04 - accuracy: 0.8603 - val_loss: 8.9490e-04 - val_accuracy: 0.8270\nEpoch 35/40\n468/468 [==============================] - 12s 25ms/step - loss: 8.0957e-04 - accuracy: 0.8589 - val_loss: 8.3355e-04 - val_accuracy: 0.8443\nEpoch 36/40\n468/468 [==============================] - 11s 24ms/step - loss: 8.3978e-04 - accuracy: 0.8579 - val_loss: 8.0487e-04 - val_accuracy: 0.8785\nEpoch 37/40\n468/468 [==============================] - 11s 24ms/step - loss: 7.9110e-04 - accuracy: 0.8619 - val_loss: 7.6218e-04 - val_accuracy: 0.8735\nEpoch 38/40\n468/468 [==============================] - 11s 24ms/step - loss: 7.8324e-04 - accuracy: 0.8616 - val_loss: 8.1015e-04 - val_accuracy: 0.8559\nEpoch 39/40\n468/468 [==============================] - 11s 23ms/step - loss: 7.7865e-04 - accuracy: 0.8618 - val_loss: 8.5467e-04 - val_accuracy: 0.8634\nEpoch 40/40\n468/468 [==============================] - 11s 24ms/step - loss: 7.6717e-04 - accuracy: 0.8618 - val_loss: 7.5523e-04 - val_accuracy: 0.8453\n","name":"stdout"},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f2136513950>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = convolutional_model.evaluate(test_dataset, steps=10)","execution_count":10,"outputs":[{"output_type":"stream","text":"10/10 [==============================] - 0s 7ms/step - loss: 7.5057e-04 - accuracy: 0.8451\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"convolutional_model.save('mymodel.h5')","execution_count":12,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-ead67034a207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mymodel.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}